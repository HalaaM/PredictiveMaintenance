{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2: Model Building & Evaluation\n",
    "Using the training and test data sets we constructed in the `Code/1_data_ingestion_and_preparation.ipynb` Jupyter notebook, this notebook builds a LSTM network for scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict failure in aircraft engines. We will store the model for deployment in an Azure web service which we build in the `Code/3_operationalization.ipynb` Jupyter notebook.\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/Azure/azureml-examples/blob/main/sdk/python/using-mlflow/train-and-log/keras_mnist_with_mlflow.ipynb\n",
    "https://github.com/Azure/azureml-examples/blob/main/sdk/python/using-mlflow/model-management/model_management.ipynb\n",
    "https://github.com/Azure/azureml-examples/blob/main/sdk/python/using-mlflow/deploy/mlflow_sdk_online_endpoints.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-ml\n",
      "  Downloading azure_ai_ml-1.11.1-py3-none-any.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.65.0)\n",
      "Collecting azure-storage-file-share<13.0.0\n",
      "  Downloading azure_storage_file_share-12.14.2-py3-none-any.whl (266 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.4/266.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Collecting marshmallow<4.0.0,>=3.5\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (6.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (2.7.0)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.4.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.27.1)\n",
      "Collecting pydash<7.0.6,>=6.0.0\n",
      "  Downloading pydash-7.0.5-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.1.9)\n",
      "Collecting colorama<0.5.0\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.6.3)\n",
      "Collecting strictyaml<2.0.0\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: isodate in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (0.6.1)\n",
      "Collecting azure-storage-file-datalake<13.0.0\n",
      "  Downloading azure_storage_file_datalake-12.13.2-py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.8/249.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.31.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (41.0.1)\n",
      "Collecting azure-core<2.0.0,>=1.23.0\n",
      "  Downloading azure_core-1.29.4-py3-none-any.whl (192 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-storage-blob<13.0.0,>=12.10.0\n",
      "  Downloading azure_storage_blob-12.18.3-py3-none-any.whl (392 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.0/393.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (1.3.10)\n",
      "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (23.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2023.5.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (1.13.0)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.0.0)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.22.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (1.15.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (3.15.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml) (2.21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.20.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.59.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.19.6)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.7.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\n",
      "Installing collected packages: pydash, marshmallow, colorama, strictyaml, azure-core, azure-storage-file-share, azure-storage-blob, azure-storage-file-datalake, azure-ai-ml\n",
      "  Attempting uninstall: azure-core\n",
      "    Found existing installation: azure-core 1.27.1\n",
      "    Uninstalling azure-core-1.27.1:\n",
      "      Successfully uninstalled azure-core-1.27.1\n",
      "  Attempting uninstall: azure-storage-blob\n",
      "    Found existing installation: azure-storage-blob 12.13.0\n",
      "    Uninstalling azure-storage-blob-12.13.0:\n",
      "      Successfully uninstalled azure-storage-blob-12.13.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azureml-mlflow 1.51.0 requires azure-storage-blob<=12.13.0,>=12.5.0, but you have azure-storage-blob 12.18.3 which is incompatible.\n",
      "azureml-core 1.51.0.post1 requires packaging<=23.0,>=20.0, but you have packaging 23.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed azure-ai-ml-1.11.1 azure-core-1.29.4 azure-storage-blob-12.18.3 azure-storage-file-datalake-12.13.2 azure-storage-file-share-12.14.2 colorama-0.4.6 marshmallow-3.20.1 pydash-7.0.5 strictyaml-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install azureml  \n",
    "#%pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import random\n",
    "import string\n",
    "\n",
    "import urllib\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn import datasets\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "\n",
    "from azure.ai.ml import MLClient, Input\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/14 14:12:20 INFO mlflow.tracking.fluent: Experiment with name 'LSTM-PD-classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1697292740901, experiment_id='5080febc-a68b-4204-893c-4e82eec28000', last_update_time=None, lifecycle_stage='active', name='LSTM-PD-classifier', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name=\"LSTM-PD-classifier\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature data set\n",
    "\n",
    "We have previously created the labeled data set in the `Code\\1_Data Ingestion and Preparation.ipynb` Jupyter notebook and stored it in local persistant storage. We define the storage locations for both the notebook input and output here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These file names detail the data files. \n",
    "TRAIN_DATA = 'PM_train_files.pkl'\n",
    "TEST_DATA = 'PM_test_files.pkl'\n",
    "\n",
    "# We'll serialize the model in json format\n",
    "LSTM_MODEL = 'modellstm.json'\n",
    "\n",
    "# and store the weights in h5\n",
    "MODEL_WEIGHTS = 'modellstm.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and dump a short summary of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.292784</td>\n",
       "      <td>0.272113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.652720</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.557471</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382530</td>\n",
       "      <td>0.463920</td>\n",
       "      <td>0.261985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.667219</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.304598</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406627</td>\n",
       "      <td>0.259865</td>\n",
       "      <td>0.316003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.574979</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274096</td>\n",
       "      <td>0.434707</td>\n",
       "      <td>0.211850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.707539</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.440375</td>\n",
       "      <td>0.307394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
       "5   1      6  0.252874  0.416667       0.0  0.0  0.268072  0.292784  0.272113   \n",
       "6   1      7  0.557471  0.583333       0.0  0.0  0.382530  0.463920  0.261985   \n",
       "7   1      8  0.304598  0.750000       0.0  0.0  0.406627  0.259865  0.316003   \n",
       "8   1      9  0.545977  0.583333       0.0  0.0  0.274096  0.434707  0.211850   \n",
       "9   1     10  0.310345  0.583333       0.0  0.0  0.150602  0.440375  0.307394   \n",
       "\n",
       "    s5  ...  s16       s17  s18  s19       s20       s21  RUL  label1  label2  \\\n",
       "0  0.0  ...  0.0  0.333333  0.0  0.0  0.713178  0.724662  191       0       0   \n",
       "1  0.0  ...  0.0  0.333333  0.0  0.0  0.666667  0.731014  190       0       0   \n",
       "2  0.0  ...  0.0  0.166667  0.0  0.0  0.627907  0.621375  189       0       0   \n",
       "3  0.0  ...  0.0  0.333333  0.0  0.0  0.573643  0.662386  188       0       0   \n",
       "4  0.0  ...  0.0  0.416667  0.0  0.0  0.589147  0.704502  187       0       0   \n",
       "5  0.0  ...  0.0  0.250000  0.0  0.0  0.651163  0.652720  186       0       0   \n",
       "6  0.0  ...  0.0  0.333333  0.0  0.0  0.744186  0.667219  185       0       0   \n",
       "7  0.0  ...  0.0  0.250000  0.0  0.0  0.643411  0.574979  184       0       0   \n",
       "8  0.0  ...  0.0  0.333333  0.0  0.0  0.705426  0.707539  183       0       0   \n",
       "9  0.0  ...  0.0  0.416667  0.0  0.0  0.627907  0.794256  182       0       0   \n",
       "\n",
       "   cycle_norm  \n",
       "0    0.000000  \n",
       "1    0.002770  \n",
       "2    0.005540  \n",
       "3    0.008310  \n",
       "4    0.011080  \n",
       "5    0.013850  \n",
       "6    0.016620  \n",
       "7    0.019391  \n",
       "8    0.022161  \n",
       "9    0.024931  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle(TRAIN_DATA)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271084</td>\n",
       "      <td>0.176150</td>\n",
       "      <td>0.217421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.624827</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271084</td>\n",
       "      <td>0.268149</td>\n",
       "      <td>0.381330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400602</td>\n",
       "      <td>0.214737</td>\n",
       "      <td>0.314652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.591273</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201807</td>\n",
       "      <td>0.485066</td>\n",
       "      <td>0.506921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.770367</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259036</td>\n",
       "      <td>0.309789</td>\n",
       "      <td>0.276671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "5   1      6  0.568966  0.750000       0.0  0.0  0.271084  0.176150  0.217421   \n",
       "6   1      7  0.500000  0.666667       0.0  0.0  0.271084  0.268149  0.381330   \n",
       "7   1      8  0.534483  0.500000       0.0  0.0  0.400602  0.214737  0.314652   \n",
       "8   1      9  0.293103  0.500000       0.0  0.0  0.201807  0.485066  0.506921   \n",
       "9   1     10  0.356322  0.416667       0.0  0.0  0.259036  0.309789  0.276671   \n",
       "\n",
       "    s5  ...  s16       s17  s18  s19       s20       s21  cycle_norm  RUL  \\\n",
       "0  0.0  ...  0.0  0.333333  0.0  0.0  0.558140  0.661834    0.000000  142   \n",
       "1  0.0  ...  0.0  0.416667  0.0  0.0  0.682171  0.686827    0.002770  141   \n",
       "2  0.0  ...  0.0  0.416667  0.0  0.0  0.728682  0.721348    0.005540  140   \n",
       "3  0.0  ...  0.0  0.250000  0.0  0.0  0.666667  0.662110    0.008310  139   \n",
       "4  0.0  ...  0.0  0.166667  0.0  0.0  0.658915  0.716377    0.011080  138   \n",
       "5  0.0  ...  0.0  0.333333  0.0  0.0  0.596899  0.624827    0.013850  137   \n",
       "6  0.0  ...  0.0  0.250000  0.0  0.0  0.550388  0.691798    0.016620  136   \n",
       "7  0.0  ...  0.0  0.416667  0.0  0.0  0.705426  0.591273    0.019391  135   \n",
       "8  0.0  ...  0.0  0.250000  0.0  0.0  0.744186  0.770367    0.022161  134   \n",
       "9  0.0  ...  0.0  0.250000  0.0  0.0  0.565891  0.673571    0.024931  133   \n",
       "\n",
       "   label1  label2  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "5       0       0  \n",
       "6       0       0  \n",
       "7       0       0  \n",
       "8       0       0  \n",
       "9       0       0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(TEST_DATA)\n",
    "\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "The traditional predictive maintenance machine learning models are based on feature engineering, the manual construction of variable using domain expertise and intuition. This usually makes these models hard to reuse as the feature are specific to the problem scenario and the available data may vary between customers. Perhaps the most attractive advantage of deep learning they automatically do feature engineering from the data, eliminating the need for the manual feature engineering step.\n",
    "\n",
    "When using LSTMs in the time-series domain, one important parameter is the sequence length, the window to examine for failure signal. This may be viewed as picking a `window_size` (i.e. 5 cycles) for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3). The rolling features included rolling mean and rolling standard deviation over the 5 cycles for each of the 21 sensor values. In deep learning, we allow the LSTMs to extract abstract features out of the sequence of sensor values within the window. The expectation is that patterns within these sensor values will be automatically encoded by the LSTM.\n",
    "\n",
    "Another critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. Computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing over such a long period. LSTMs are able to use larger window sizes and use all the information in the window as input. \n",
    "\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/ contains more information on the details of LSTM networks.\n",
    "\n",
    "This notebook illustrates the LSTM approach to binary classification using a sequence_length of 50 cycles to predict the probability of engine failure within 30 days.\n",
    "\n",
    "We are going to use autologging capabilities in MLflow to track parameters and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [Keras LSTM](https://keras.io/layers/recurrent/) with [Tensorflow](https://tensorflow.org) as a backend. Here layers expect an input in the shape of an array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step.\n",
    "\n",
    "We define a function to generate this array, as we'll use it repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences are built from the features (sensor and settings) values across the time steps (cycles) within each engine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setting1', 'setting2', 'setting3', 'cycle_norm', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n"
     ]
    }
   ],
   "source": [
    "# pick the feature columns \n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "key_cols = ['id', 'cycle']\n",
    "label_cols = ['label1', 'label2', 'RUL']\n",
    "\n",
    "input_features = test_df.columns.values.tolist()\n",
    "sensor_cols = [x for x in input_features if x not in set(key_cols)]\n",
    "sensor_cols = [x for x in sensor_cols if x not in set(label_cols)]\n",
    "sensor_cols = [x for x in sensor_cols if x not in set(sequence_cols)]\n",
    "\n",
    "# The time is sequenced along\n",
    "# This may be a silly way to get these column names, but it's relatively clear\n",
    "sequence_cols.extend(sensor_cols)\n",
    "\n",
    "print(sequence_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_df['id'].unique())\n",
    "\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a function to label these sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only be using the LSTM to predict failure within the next 30 days (`label1`). To predict other labels, we could change this call before building the LSTM network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network\n",
    "\n",
    "Building a Neural Net requires determining the network architecture. In this scenario we will build a network of only 2 layers, with dropout. The first LSTM layer with 100 units, one for each input sequence, followed by another LSTM layer with 50 units. We will also apply dropout each LSTM layer to control overfitting. The final dense output layer employs a sigmoid activation corresponding to the binary classification requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 14:12:43.215429: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 100)           50400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 100)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,651\n",
      "Trainable params: 80,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build the network\n",
    "# Feature weights\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "# LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# The first layer\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# The second layer\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "\n",
    "# Plus a 20% dropout rate\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense sigmoid layer\n",
    "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "\n",
    "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Verify the architecture \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 15 seconds per epoch to build this model on a DS4_V2 standard [Data Science Virtual Machine for Linux (Ubuntu)](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu) using only CPU compute.\n",
    "\n",
    "As soon as the train method is executed, MLflow will stat a run in Azure ML to start tracking the experiment's run. However, it is always a good idea to start the run manually so you have the run ID at hand quickly. This is not required though.\n",
    "\n",
    "Important: When running training routines in Azure ML as jobs, you don't need to start or end the run in your training code as it is automatically done for you by Azure ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 20s 180ms/step - loss: 0.2872 - accuracy: 0.8797 - val_loss: 0.1912 - val_accuracy: 0.9226\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.1140 - accuracy: 0.9571 - val_loss: 0.0725 - val_accuracy: 0.9751\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 9s 142ms/step - loss: 0.0913 - accuracy: 0.9638 - val_loss: 0.0613 - val_accuracy: 0.9754\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 9s 143ms/step - loss: 0.0761 - accuracy: 0.9677 - val_loss: 0.0553 - val_accuracy: 0.9776\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 9s 143ms/step - loss: 0.0687 - accuracy: 0.9710 - val_loss: 0.0864 - val_accuracy: 0.9639\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.0686 - accuracy: 0.9715 - val_loss: 0.0688 - val_accuracy: 0.9709\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 0.0725 - accuracy: 0.9700 - val_loss: 0.0618 - val_accuracy: 0.9731\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 9s 147ms/step - loss: 0.0626 - accuracy: 0.9738 - val_loss: 0.0439 - val_accuracy: 0.9827\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0497 - accuracy: 0.9788 - val_loss: 0.0552 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 9s 151ms/step - loss: 0.0539 - accuracy: 0.9763 - val_loss: 0.0551 - val_accuracy: 0.9776\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 0.0543 - accuracy: 0.9768 - val_loss: 0.0485 - val_accuracy: 0.9779\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 9s 150ms/step - loss: 0.0517 - accuracy: 0.9787 - val_loss: 0.0451 - val_accuracy: 0.9840\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 9s 148ms/step - loss: 0.0573 - accuracy: 0.9766 - val_loss: 0.0665 - val_accuracy: 0.9661\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 9s 147ms/step - loss: 0.0504 - accuracy: 0.9788 - val_loss: 0.0583 - val_accuracy: 0.9738\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 9s 147ms/step - loss: 0.0500 - accuracy: 0.9774 - val_loss: 0.0475 - val_accuracy: 0.9786\n",
      "1/1 [==============================] - 1s 789ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplxss6tj8/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplxss6tj8/model/data/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 58s, sys: 53.1 s, total: 7min 52s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febe83894c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the network\n",
    "model.fit(seq_array, # Training features\n",
    "          label_array, # Training labels\n",
    "          epochs=20,   # We'll stop after 20 epochs\n",
    "          batch_size=200, # \n",
    "          validation_split=0.20, # Use 20% of data to evaluate the loss. (val_loss)\n",
    "          verbose=1, #\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', # Monitor the validation loss\n",
    "                                                     min_delta=0,    # until it doesn't change (or gets worse)\n",
    "                                                     patience=7,  # patience > 1 so it continutes if it is not consistently improving\n",
    "                                                     verbose=0, \n",
    "                                                     mode='auto')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimized the network weights on the training set accuracy, which we examine here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 5s 58ms/step - loss: 0.0438 - accuracy: 0.9807\n",
      "Training Accurracy: 0.9806793928146362\n"
     ]
    }
   ],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Training Accurracy: {}'.format(scores[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the training set performance by looking at the model confusion matrix. Accurate predictions lie along the diagonal of the matrix, errors are on the off diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 8s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "\n",
    "\n",
    "y_true = label_array\n",
    "\n",
    "y_pred=model.predict(seq_array) \n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done with the training, let's end the run:\n",
    "\n",
    "Important: Remember that when training with jobs, you should not start/end runs manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the parameters that got logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_split</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuffle</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_epoch</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_steps</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_batch_size</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_queue_size</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_multiprocessing</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monitor</th>\n",
       "      <td>val_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_delta</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patience</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restore_best_weights</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_name</th>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_weight_decay</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_clipnorm</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_global_clipnorm</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_clipvalue</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_use_ema</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_ema_momentum</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_ema_overwrite_frequency</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_jit_compile</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_is_legacy_optimizer</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_learning_rate</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_beta_1</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_beta_2</th>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_epsilon</th>\n",
       "      <td>1e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt_amsgrad</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Value\n",
       "epochs                             20\n",
       "batch_size                        200\n",
       "validation_split                  0.2\n",
       "shuffle                          True\n",
       "class_weight                     None\n",
       "sample_weight                    None\n",
       "initial_epoch                       0\n",
       "steps_per_epoch                  None\n",
       "validation_steps                 None\n",
       "validation_batch_size            None\n",
       "validation_freq                     1\n",
       "max_queue_size                     10\n",
       "workers                             1\n",
       "use_multiprocessing             False\n",
       "monitor                      val_loss\n",
       "min_delta                           0\n",
       "patience                            7\n",
       "baseline                         None\n",
       "restore_best_weights            False\n",
       "opt_name                         Adam\n",
       "opt_weight_decay                 None\n",
       "opt_clipnorm                     None\n",
       "opt_global_clipnorm              None\n",
       "opt_clipvalue                    None\n",
       "opt_use_ema                     False\n",
       "opt_ema_momentum                 0.99\n",
       "opt_ema_overwrite_frequency      None\n",
       "opt_jit_compile                 False\n",
       "opt_is_legacy_optimizer         False\n",
       "opt_learning_rate               0.001\n",
       "opt_beta_1                        0.9\n",
       "opt_beta_2                      0.999\n",
       "opt_epsilon                     1e-07\n",
       "opt_amsgrad                     False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = mlflow.get_run(run.info.run_id)\n",
    "pd.DataFrame(data=[run.data.params], index=[\"Value\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the metrics values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.049972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_accuracy</th>\n",
       "      <td>0.978574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.977367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.047456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopped_epoch</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Value\n",
       "loss            0.049972\n",
       "val_accuracy    0.978574\n",
       "accuracy        0.977367\n",
       "val_loss        0.047456\n",
       "stopped_epoch  14.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[run.data.metrics], index=[\"Value\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore artifacts that got logged in the run. This requires to use the MLflow client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=-1, is_dir=True, path='model'>,\n",
       " <FileInfo: file_size=-1, is_dir=False, path='model_summary.txt'>,\n",
       " <FileInfo: file_size=-1, is_dir=True, path='tensorboard_logs'>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.list_artifacts(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this example, three artifacts are availble in the run:\n",
    "\n",
    "- **model**, the path where the model is stored. Note that this artifact is a directory.\n",
    "- **model_summary.txt** -> Contains a summary of the training process of the TensorFlow model. This is TensorFlow\n",
    "- **tensorboard_logs** -> The TensorBoard logs. Note that this artifact is a directory.\n",
    "specific.\n",
    "\n",
    "You can download any artifact using the method download_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = mlflow.artifacts.download_artifacts(\n",
    "    run_id=run.info.run_id, artifact_path=\"model_summary.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model: \"sequential\"\\n', '_________________________________________________________________\\n', ' Layer (type)                Output Shape              Param #   \\n', '=================================================================\\n', ' lstm (LSTM)                 (None, 50, 100)           50400     \\n', '                                                                 \\n', ' dropout (Dropout)           (None, 50, 100)           0         \\n', '                                                                 \\n', ' lstm_1 (LSTM)               (None, 50)                30200     \\n', '                                                                 \\n', ' dropout_1 (Dropout)         (None, 50)                0         \\n', '                                                                 \\n', ' dense (Dense)               (None, 1)                 51        \\n', '                                                                 \\n', '=================================================================\\n', 'Total params: 80,651\\n', 'Trainable params: 80,651\\n', 'Non-trainable params: 0\\n', '_________________________________________________________________']\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"r\") as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**autolog** has also logged the model for us, let's try to get it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = mlflow.keras.load_model(f\"runs:/{run.info.run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 9s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(seq_array).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12298,   233],\n",
       "       [   69,  3031]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have many more healthy cycles than failure cycles, we also look at precision and recall. In all cases, we assume the model threshold is at $Pr = 0.5$. In order to tune this, we need to look at a test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.9286151960784313 \n",
      " Training Recall:  0.977741935483871 \n",
      " Training F1 Score: 0.9525455688246387\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print( 'Training Precision: ', precision, '\\n', 'Training Recall: ', recall, '\\n', 'Training F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "Next, we look at the performance on the test data. Only the last cycle data for each engine id in the test data is kept for testing purposes. In order to compare the results to the template, we pick the last sequence for each id in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 50, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
    "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
    "\n",
    "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "seq_array_test_last.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also ned the test set labels in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 50, 25)\n",
      "(93, 1)\n"
     ]
    }
   ],
   "source": [
    "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n",
    "\n",
    "label_array_test_last = test_df.groupby('id')['label1'].nth(-1)[y_mask].values\n",
    "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
    "label_array_test_last.shape\n",
    "\n",
    "print(seq_array_test_last.shape)\n",
    "print(label_array_test_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the model with the test data. We report the model accuracy on the test set, and compare it to the training accuracy. By definition, the training accuracy should be optimistic since the model was optimized for those observations. The test set accuracy is more general, and simulates how the model was intended to be used to predict forward in time. This is the number we should use for reporting how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.0545 - accuracy: 0.9677 - 81ms/epoch - 27ms/step\n",
      "Test Accurracy: 0.9677419066429138\n"
     ]
    }
   ],
   "source": [
    "# test metrics\n",
    "scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
    "print('Test Accurracy: {}'.format(scores_test[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for the test set confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step\n",
      "Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[66,  2],\n",
       "       [ 1, 24]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "y_pred_test = model.predict(seq_array_test_last)\n",
    "y_pred_test = np.round(y_pred_test)\n",
    "y_true_test = label_array_test_last\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix uses absolute counts, so comparing the test and training set confusion matrices is difficult. Instead, it is  better to use precision and recall. \n",
    "\n",
    " * _Precision_ measures how accurate your model predicts failures. What percentage of the failure predictions are actually failures.\n",
    " * _Recall_ measures how well the model captures thos failures. What percentage of the true failures did your model capture.\n",
    " \n",
    "These measures are tightly coupled, and you can typically only choose to maximize one of them (by manipulating the probability threshold) and have to accept the other as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision:  0.9230769230769231 \n",
      " Test Recall:  0.96 \n",
      " Test F1 Score: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
    "print( 'Test Precision: ', precision_test, '\\n', 'Test Recall: ', recall_test, '\\n', 'Test F1 Score:', f1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model  \n",
    "\n",
    "The LSTM network is made up of two components, the architecture and the model weights. We'll save these model components in two files, the architecture in a `json` file that the `keras` package can use to rebuild the model, and the weights in an `HDF5` heirachy that rebuild the exact model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Save the model for operationalization: https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "\n",
    " \n",
    "# save model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(LSTM_MODEL, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(MODEL_WEIGHTS)\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the save operations, we can reload the model files into a test model `loaded_model` and rescore the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(LSTM_MODEL, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(MODEL_WEIGHTS)\n",
    "\n",
    "loaded_model.compile('sgd','mse')\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model constructed from storage can be used to predict the probability of engine failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/489 [==============================] - 9s 17ms/step\n",
      "(15631, 1)\n",
      "[[2.3313487e-05]\n",
      " [2.3846611e-05]\n",
      " [2.4460063e-05]\n",
      " ...\n",
      " [9.9970084e-01]\n",
      " [9.9972272e-01]\n",
      " [9.9975330e-01]]\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.predict(seq_array,verbose=1)\n",
    "print(score.shape)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file written shared folder\n"
     ]
    }
   ],
   "source": [
    "with open(LSTM_MODEL, 'wt') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    print(\"json file written shared folder\")\n",
    "    json_file.close()\n",
    "    \n",
    "model.save_weights(os.path.join(MODEL_WEIGHTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Register and Deploy\n",
    "\n",
    "#### Creating models from an existing run\n",
    "If you have an Mlflow model logged inside of a run and you want to register it in a registry, you can do that by using the experiment and run ID information from the run. Let's create a simple experiment and run to demonstrate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18670e88-3a7f-48e3-a07e-bc3da19bdc50\n"
     ]
    }
   ],
   "source": [
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "last_run = mlflow.search_runs(exp.experiment_id, output_format=\"list\")[-1]\n",
    "print(last_run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mlflow-PD_LSTM-model\"\n",
    "artifact_path = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now register the model from the local path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'mlflow-PD_LSTM-model'.\n",
      "2023/10/14 14:17:26 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: mlflow-PD_LSTM-model, version 1\n",
      "Created version '1' of model 'mlflow-PD_LSTM-model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1697293046092, current_stage='None', description='', last_updated_timestamp=1697293046092, name='mlflow-PD_LSTM-model', run_id='18670e88-3a7f-48e3-a07e-bc3da19bdc50', run_link='', source='azureml://eastus2.api.azureml.ms/mlflow/v2.0/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourceGroups/RG-ML-PredMaint/providers/Microsoft.MachineLearningServices/workspaces/ML-PredMaint/experiments/5080febc-a68b-4204-893c-4e82eec28000/runs/18670e88-3a7f-48e3-a07e-bc3da19bdc50/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.register_model(f\"runs:/{last_run.info.run_id}/{artifact_path}\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online Endpoints have the concept of **Endpoint** and **Deployment**. An endpoint represents the API that customers uses to consume the model, while a deployment indicates the specific implementation of that API. This distinction allows users to decouple the API from the implementation and to change the underlying implementation without affecting the consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: PD-LSTM-c022t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a unique endpoint name by including a random suffix\n",
    "allowed_chars = string.ascii_lowercase + string.digits\n",
    "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
    "endpoint_name = \"PD-LSTM-\" + endpoint_suffix\n",
    "\n",
    "print(f\"Endpoint name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create an MLflow deployment client for Azure Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_client = get_deploy_client(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the endpoint with basic configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = deployment_client.create_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the scoring URI from the endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pd-lstm-c022t.eastus2.inference.ml.azure.com/score\n"
     ]
    }
   ],
   "source": [
    "scoring_uri = deployment_client.get_endpoint(endpoint=endpoint_name)[\"properties\"][\n",
    "    \"scoringUri\"\n",
    "]\n",
    "print(scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the hardware requirements of your deployment, you need to create a JSON file with the desired configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_config = {\n",
    "    \"instance_type\": \"Standard_DS3_v2\",\n",
    "    \"instance_count\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the configuration to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deployment_config_path = \"deployment_config.json\"\n",
    "with open(deployment_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(deploy_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method **create_deployment** allows you to create a simple deployment using the configuration indicated in the configuration file. We are going to name this deployment \"default\".  This step may take 10-20 minutes, you can monitor it in the Azure ML Portal as well under Endpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................"
     ]
    }
   ],
   "source": [
    "version = 1\n",
    "\n",
    "deployment = deployment_client.create_deployment(\n",
    "    name=deployment_name,\n",
    "    endpoint=endpoint_name,\n",
    "    model_uri=f\"models:/{model_name}/{version}\",\n",
    "    config={\"deploy-config-file\": deployment_config_path},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, new deployments receive none of the traffic from the endpoint. Let's assign all of it to the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_config = {\"traffic\": {deployment_name: 100}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the configuration to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_config_path = \"traffic_config.json\"\n",
    "with open(traffic_config_path, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(traffic_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the key endpoint-config-file to update the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourceGroups/rg-ml-predmaint/providers/Microsoft.MachineLearningServices/workspaces/ml-predmaint/onlineEndpoints/pd-lstm-c022t',\n",
       " 'name': 'pd-lstm-c022t',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces/onlineEndpoints',\n",
       " 'systemData': {'createdBy': 'Shep Sheppard',\n",
       "  'createdAt': '2023-10-14T14:17:40.747507Z',\n",
       "  'lastModifiedAt': '2023-10-14T14:17:40.747507Z'},\n",
       " 'tags': {},\n",
       " 'location': 'eastus2',\n",
       " 'identity': {'principalId': 'b82e32db-6ad3-4569-bbc4-3bc247e58df8',\n",
       "  'tenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n",
       "  'type': 'SystemAssigned'},\n",
       " 'kind': 'Managed',\n",
       " 'properties': {'authMode': 'AMLToken',\n",
       "  'properties': {'azureml.mlflow_client_endpoint': 'True',\n",
       "   'azureml.onlineendpointid': '/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/resourcegroups/rg-ml-predmaint/providers/microsoft.machinelearningservices/workspaces/ml-predmaint/onlineendpoints/pd-lstm-c022t',\n",
       "   'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/d83b98a9-eaa6-475f-9ae6-1ef35394a1e5/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:4d432f13-1fef-4273-a81e-93bdcd799dc0:19a321dc-cbdc-440e-9f5d-05ce3b66871e?api-version=2022-02-01-preview'},\n",
       "  'scoringUri': 'https://pd-lstm-c022t.eastus2.inference.ml.azure.com/score',\n",
       "  'swaggerUri': 'https://pd-lstm-c022t.eastus2.inference.ml.azure.com/swagger.json',\n",
       "  'mirrorTraffic': {},\n",
       "  'provisioningState': 'Succeeded',\n",
       "  'publicNetworkAccess': 'Enabled',\n",
       "  'traffic': {'default': 100}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployment_client.update_endpoint(\n",
    "    endpoint=endpoint_name,\n",
    "    config={\"endpoint-config-file\": traffic_config_path},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are ready, delete the created resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deployment_client.delete_deployment(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
